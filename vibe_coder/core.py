from langchain_community.llms import Ollama
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate
from .arch_linux import ArchLinuxEnvironment
from .prompts import VIBE_CODER_SYSTEM_PROMPT
import json
from typing import Dict, Any, List

class VirtualVibeCoder:
    def __init__(self, model_name: str = "deepseek-r1:8b"):
        self.llm = Ollama(model=model_name)
        self.environment = ArchLinuxEnvironment()
        self.conversation_history: List[Dict[str, str]] = []
        
    def _format_messages(self, user_input: str) -> List[Dict[str, str]]:
        """Format messages for the LLM"""
        messages = [
            {"role": "system", "content": VIBE_CODER_SYSTEM_PROMPT},
        ]
        
        # Add conversation history
        for msg in self.conversation_history[-6:]:  # Keep last 6 exchanges
            messages.append(msg)
            
        messages.append({"role": "user", "content": user_input})
        return messages
    
    def process_request(self, user_input: str) -> str:
        """Process a user request using vibe coding principles"""
        try:
            # Get system context
            tools_info = f"Available tools: {', '.join([k for k, v in self.environment.available_tools.items() if v])}"
            current_dir = self.environment.terminal.get_current_directory()
            context = f"Current directory: {current_dir}\n{tools_info}\n\nUser request: {user_input}"
            
            full_input = f"{context}\n\nPlease provide a step-by-step approach to solve this using vibe coding principles. Include specific commands to execute and reasoning for each step."
            
            messages = self._format_messages(full_input)
            
            # Get LLM response
            response = self.llm.invoke(json.dumps(messages))
            
            # Parse and execute the plan
            result = self._execute_plan(response, user_input)
            
            # Update conversation history
            self.conversation_history.append({"role": "user", "content": user_input})
            self.conversation_history.append({"role": "assistant", "content": response + "\n\n" + result})
            
            return f"## Vibe Coder Response\n\n{response}\n\n## Execution Results\n\n{result}"
            
        except Exception as e:
            return f"Error processing request: {str(e)}"
    
    def _execute_plan(self, plan: str, original_request: str) -> str:
        """Execute the plan generated by the LLM"""
        execution_log = []
        
        # Parse the plan for executable commands
        lines = plan.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            if line.startswith('```') and current_section is None:
                current_section = ""
            elif line.startswith('```') and current_section is not None:
                # End of code block - execute it
                if current_section.strip():
                    execution_log.append(f"Executing code block:\n{current_section}")
                    result = self._execute_code_block(current_section)
                    execution_log.append(f"Result: {result}")
                current_section = None
            elif current_section is not None:
                current_section += line + '\n'
            elif line.startswith('sudo ') or line.startswith('pacman ') or line.startswith('git '):
                # Execute individual commands
                execution_log.append(f"Executing command: {line}")
                stdout, stderr, code = self.environment.terminal.execute_command(line)
                execution_log.append(f"Exit code: {code}\nStdout: {stdout}\nStderr: {stderr}")
        
        return '\n'.join(execution_log)
    
    def _execute_code_block(self, code: str) -> str:
        """Execute a code block by writing to a file and running it"""
        # Determine file type and interpreter
        if 'def ' in code or 'import ' in code:
            # Python code
            filename = 'temp_script.py'
            interpreter = 'python3'
        elif 'function ' in code or 'const ' in code or 'let ' in code:
            # JavaScript code
            filename = 'temp_script.js'
            interpreter = 'node'
        else:
            # Assume shell script
            filename = 'temp_script.sh'
            interpreter = 'bash'
        
        # Write and execute
        success, message = self.environment.terminal.write_file(filename, code)
        if not success:
            return f"Failed to write file: {message}"
        
        stdout, stderr, code = self.environment.terminal.execute_command(f"{interpreter} {filename}")
        
        # Clean up
        self.environment.terminal.execute_command(f"rm {filename}")
        
        return f"Exit code: {code}\nOutput: {stdout}\nErrors: {stderr}"
    
    def get_environment_info(self) -> str:
        """Get information about the current environment"""
        tools = [tool for tool, available in self.environment.available_tools.items() if available]
        current_dir = self.environment.terminal.get_current_directory()
        
        return f"""
## Arch Linux Environment
- Current directory: {current_dir}
- Available tools: {', '.join(tools)}
- Sudo privileges: Available
- Model: deepseek-r1:8b (local)
        """