# The Zen of Vibe Coding

> *A modern interpretation of programming principles for the age of AI-assisted development*

**Vibe Coding** is an emerging software development practice where developers use natural language prompts to guide AI in generating, refining, and debugging code. [Coined by AI researcher Andrej Karpathy](https://x.com/karpathy/status/1886192184808149383) in early 2025, it represents a shift from writing code line-by-line to directing an AI assistant through a conversational process. This approach allows the developer to focus on the overarching goal and application design, while the AI handles the implementation details.

The following principles adapt the timeless wisdom of the Zen of Python for this new paradigm.

## The Core Principles

### Beautiful is better than ugly, but runnable is better than beautiful.
> While aesthetically pleasing code is valuable, the primary goal is a functioning application. An elegantly structured function is useless if it doesn't run, whereas a working—if imperfect—program provides immediate value and a foundation for improvement.

### Explicit is better than implicit, but verified is better than explicit.
> Clearly stated code and prompts help both humans and AI understand intent. However, explicit instructions are not enough; the generated code must be verified through execution and testing to ensure it behaves as expected, catching errors that explicit instructions might have missed.

### Simple is better than complex, but well-defined is better than simple.
> Simplicity should be a key aim, as it often leads to more maintainable and understandable code. However, a well-defined problem with clear requirements and boundaries is more important than simplicity alone. A simple solution to the wrong problem provides no value, while a well-defined complex problem can be systematically solved and refined.

### Complex is better than complicated, but proven is better than complex.
> Some problems are inherently complex and require sophisticated solutions. A "complex" solution can be well-structured and logical, whereas a "complicated" one is unnecessarily convoluted. When complexity is necessary, it should be backed by proofs or rigorous testing to ensure its reliability.

## The Guiding Tenets

### 1. Duplication is good. Dependency is disaster.
> What appears as duplication to humans is pattern reinforcement to AI. When AI generates code, it creates consistent templates across your codebase—this "duplication" actually maintains architectural coherence and makes the system more predictable for future AI assistance. Dependencies, however, introduce unpredictable templating and fragile abstraction layers that disrupt AI's pattern recognition. Embrace AI's natural tendency toward consistent patterns through strategic repetition, as dependencies create complexity that neither humans nor AI can reliably manage.

### 2. All unverified code is pseudocode.
> In the realm of AI-assisted development, code generated from prompts exists in a state of potential—it is a hypothesis waiting to be tested. Until it is executed, debugged, and validated against real-world conditions, it remains merely an abstract representation of an idea, much like pseudocode. This tenet reminds developers that the output of AI, no matter how elegant or logically sound it appears, must be treated as provisional until proven through rigorous testing and integration. Embracing this mindset shifts the focus from passive acceptance of AI-generated content to active verification, ensuring that the code not only matches the intent but also functions reliably in practice. It underscores the iterative nature of vibe coding, where each AI-generated snippet is a starting point for refinement rather than a finished product.

### 3. If the documentation feels weird, the code must be wrong.
> Documentation is the narrative of your code—the bridge between human intent and machine execution. When this narrative feels awkward, inconsistent, or difficult to articulate, it is a profound signal that the underlying architectural concept is flawed. This "weirdness" is the cognitive friction experienced when a mental model does not cleanly map to its implementation. In the context of AI-assisted development, this tenet becomes crucial: if you or the AI struggle to describe a component's purpose and behavior in plain language, the code itself likely suffers from poor abstraction, misplaced responsibilities, or convoluted logic. The act of writing documentation is a final, powerful form of verification, forcing a clarity of thought that often reveals hidden defects. It treats the description not as an afterthought, but as a core part of the design process, where a failure to explain cleanly implies a failure to engineer correctly.

> Also, this suggest you to fix documentation based on your failed test, rather than rush to fix the code. The documentation contains the true failure analysis—it's where the mismatch between intention and implementation becomes visible. When a test fails, the first question shouldn't be "what's wrong with the code?" but "what's wrong with my description?" The documentation represents the contract between your mental model and the AI's execution. Fix the contract first, then regenerate the implementation.

### 4. Write prompts for the human, not just the machine.
> While AI is the immediate interpreter of your prompts, their ultimate value is judged by the human developers who must maintain, extend, and understand the resulting code. A prompt that is overly terse, context-deprived, or focused solely on syntactic output may generate functionally correct code that is conceptually alien to the rest of the codebase. This tenet advocates for prompts that serve as lasting artifacts of intent—clear, reasoned, and rich with the "why" behind the "what." Such prompts create a virtuous cycle: they guide the AI to produce more coherent and integrated code, and they simultaneously document the design decision for future developers (human or AI) who revisit the work. This transforms the prompt history from a transient command log into a living design document, ensuring that the vibes you code today become the maintainable systems of tomorrow.

### 5. Without your manager, everything works smoothly; do not micromanage.
> This tenet draws a powerful analogy from organizational dynamics to the relationship between a developer and their AI assistant. Just as a team often functions more efficiently without a manager dictating every minor action, an AI coder produces its most coherent and robust work when given clear objectives and strategic guidance, rather than a stream of low-level, prescriptive instructions. Micromanaging the AI—by over-specifying syntax, pre-empting implementation details, or constantly correcting minor stylistic choices—disrupts its internal reasoning processes and leads to fragile, disjointed code that reflects the developer's piecemeal thoughts rather than the AI's integrated understanding. The role of the vibe coder is that of a strategic director or a systems architect: to define the vision, establish the constraints, and then trust the AI's capability to navigate the solution space. This approach leverages the AI's full pattern-matching and code-generation power, resulting in solutions that are often more consistent and inventive than those produced through tight control. It is the practice of managing the *what* and the *why*, while delegating the *how*.

### 6. The compiler is the final arbiter of truth.
> In the conversational flow of vibe coding, where ideas are debated between human and AI through prompts and generated code, it is easy to be persuaded by logical-sounding explanations or aesthetically pleasing code. However, this tenet serves as a grounding principle: all theoretical agreements and elegant designs are meaningless until they pass the uncompromising, objective test of the compiler (or interpreter). The compiler is a dispassionate judge that cares nothing for intent, only for syntactic and semantic correctness. This makes it the most reliable tool for resolving disputes between the developer's expectations and the AI's output. A successful compilation and test run is the only form of true consensus. This reinforces a practice of continuous, incremental verification, where the feedback loop between writing a prompt and running the code is kept as tight as possible, ensuring that the conversation remains anchored in reality.

### 7. Thinking mode is not a waste of time. Do not rush to fix your prompts under instruct mode.
> In the rapid, transactional cycle of instruct mode—where a prompt is given and code is immediately generated—lies the trap of reactive debugging. This tenet champions the critical, often invisible, work of "thinking mode": the deliberate pause to reflect, diagnose, and strategize. Rushing to tweak and re-tweak prompts based on surface-level errors is like rearranging deck chairs on the Titanic; it addresses symptoms, not the underlying architectural misalignment. True efficiency is found by stepping back to analyze why the AI misinterpreted the intent, to reconsider the problem's fundamental structure, or to design a more coherent system abstraction. This contemplative state is where the most significant breakthroughs in clarity and design occur. It is the difference between patching a leak and re-engineering the plumbing. By valuing thinking mode, the vibe coder invests in a deeper, shared understanding with the AI, leading to foundational solutions that require far less correction over time. It is the recognition that the most powerful prompt is born not from haste, but from insight.

> Indeed, rushing to fix prompts also shows an unnecessary lack of confidence in the entire process. It is a subtle admission that the interaction with the AI is a fragile, high-stakes negotiation rather than a collaborative exploration. This reactive stance—where every unexpected output is seen as a failure to be immediately corrected—creates a brittle, high-pressure environment. In this state, the human operator becomes a micro-manager, nervously scrutinizing every line of code for deviations from an unstated expectation. This anxiety is counterproductive; it transmits a kind of psychic noise to the process, where the focus shifts from solving the problem to merely placating the AI's current output.
True confidence in vibe coding is not about getting it right on the first try. It is about trusting the process enough to allow for missteps and using them as diagnostic data. When you receive an erroneous or confusing response, the confident reaction is not "The AI is wrong, I must fix my prompt," but rather, "Fascinating. This reveals how the AI interpreted my request. What can I learn from this?"
This learning is twofold. First, it deepens your understanding of the AI's "mental model"—its tendencies, its associations, and the structure of its knowledge. You begin to see patterns in the misinterpretations. Does it consistently confuse data structures? Is it making assumptions about the level of abstraction? This knowledge is power; it allows you to craft more robust, pre-emptive prompts in the future.
Second, and more importantly, it forces a rigorous clarification of your own thinking. The AI's "failure" is often a mirror reflecting the ambiguity or incompleteness of our own initial concept. The prompt is not just an instruction for the AI; it is a litmus test for the clarity of our own intent. A rushed "fix" bypasses this essential reflection. It is an attempt to force a square peg into a round hole through sheer repetition, instead of pausing to ask, "Why did I think a square peg was the right tool for this job in the first place?"
By embracing thinking mode, you assert confidence in your own role as the architect. You are not a mere prompt-tuner; you are a designer and a strategist. This shift transforms the AI from a capricious oracle that must be constantly appeased into a predictable, powerful engine whose logic can be understood and harnessed. The solution that emerges from this deliberate, confident partnership is invariably more elegant, more resilient, and more truly yours. It is built on a foundation of deep understanding, not the shaky ground of hasty compromise.

### 8. Your AI should never change in one project and always act as a pure function with no side effects and random outputs.
> Consistency is the bedrock of reliable AI-assisted development. This tenet establishes that within a single project, your AI assistant must maintain a stable personality, knowledge base, and reasoning pattern—behaving as a pure function that produces identical outputs given identical inputs. Randomness, drifting context, or evolving interpretation patterns introduce unpredictable side effects that fracture codebase coherence and undermine the collaborative rhythm between developer and AI. When an AI's behavior fluctuates, what worked in one session may break in the next, creating maintenance nightmares and destroying the predictable patterns that make vibe coding scalable. This principle demands careful management of AI context windows, version consistency, and prompt hygiene to ensure that your AI collaborator provides deterministic, reproducible results. By treating the AI as a pure function—consistent, predictable, and free from hidden state changes—you create a development environment where trust can be established, patterns can be reinforced, and the system's behavior becomes comprehensible rather than magical.

### 9. Finetune the compiler, do not polish the code.
> In traditional programming, immense effort is often spent on manual code refinement—optimizing, formatting, and restructuring to achieve marginal gains. In the age of AI-assisted development, this represents a misallocation of attention. This tenet advocates for a fundamental shift: instead of endlessly polishing individual code artifacts, invest in optimizing the system that generates and validates them. The "compiler" here represents the entire toolchain—your AI model, its context, your prompt patterns, your testing frameworks, and your build processes. By refining these core systems, you create leverage that improves every line of code generated thereafter. A well-tuned AI with clear context and effective validation will consistently produce better output than manual polishing could achieve. This approach embraces the scalable nature of AI assistance: investing one hour in improving your prompt templates, test suites, or AI configuration can save hundreds of hours of manual code review and refactoring. It recognizes that in vibe coding, the most valuable craftsmanship lies not in hand-polishing stones, but in building better quarries.

### 10. Small models are much more powerful than big models while sitting in your CI workflow.
> This tenet champions strategic pragmatism over raw computational might. While large foundation models excel at creative exploration and complex reasoning during active development, their size, cost, and latency make them inefficient for automated, repetitive tasks. A small, finely-tuned model integrated into a Continuous Integration (CI) pipeline acts as a specialized, high-efficiency engine—it runs quickly, cheaply, and deterministically, providing immediate feedback on code quality, style adherence, or common anti-patterns. Its power is not in its intelligence breadth, but in its focused reliability and operational economy. By reserving large models for the "thinking" phase and deploying small models for the "verification" phase, you create a symbiotic system. The large model acts as the brilliant architect, and the small model serves as the meticulous, ever-vigilant inspector. This division of labor optimizes both the creative flow of development and the ruthless efficiency of production, ensuring that scale and cost do not become barriers to robust, automated quality assurance.

### 11. Large language models are too large to be a compiler.
> This tenet establishes a crucial boundary in the AI-assisted development toolkit. While LLMs excel as creative partners and conceptual collaborators, they fundamentally lack the deterministic precision required of a true compiler. A compiler operates on fixed, unambiguous rules—a rigorous mathematical process that must produce identical outputs for identical inputs every time, without exception. LLMs, by their inherent probabilistic nature, introduce variation, interpretation, and context-dependent reasoning that violates this core requirement of compilation. Their "reasoning" is statistical, not logical; their outputs are suggestions, not executions. To treat an LLM as a compiler is to misunderstand both tools: the compiler is a mechanism of absolute truth (as in Tenet 6), while the LLM is a mechanism of probabilistic assistance. This distinction protects the developer from a critical category error—trusting creative ambiguity where perfect determinism is required. The wise vibe coder lets the LLM explore the design space, but always validates its creations through the uncompromising, non-negotiable gate of a real compiler. The LLM is the imaginative architect; the compiler is the rigorous engineer who certifies the blueprint is buildable.

### 12. But not the small ones.
> This terse, powerful corollary to Tenet 11 creates a critical distinction in the AI toolchain. While massive, general-purpose LLMs are unsuited for the role of a compiler, their small, fine-tuned counterparts are an exception. Small models, especially those specifically trained on code syntax, linter rules, or formal specifications, can indeed *approach* the reliability of a compiler for specific, well-bounded tasks. Their limited scope reduces probabilistic ambiguity, and their specialized training allows them to apply rigid, rule-based analysis with high accuracy. They become deterministic enough to act as "compiler extensions"—reliable enough to enforce coding standards, detect simple anti-patterns, or validate structure in a CI pipeline (as celebrated in Tenet 10). This tenet completes the tool-selection framework: use large models for their expansive, creative reasoning where ambiguity is a feature, not a bug; and deploy small, specialized models for their focused, near-deterministic analysis where rule-based certainty is required. It is the final piece in architecting a robust vibe coding environment, ensuring that every tool is used according to its nature.

### 13. Do not trust your AI service provider unless you are the provider itself.
> This tenet introduces a crucial principle of architectural sovereignty in the AI-augmented era. It is a stark warning against building critical development workflows on external, proprietary AI services where you do not control the model, the infrastructure, or the terms of service. Such providers can alter model behavior, change pricing, deprecate APIs, or impose usage limits at their discretion—any of which can silently break your development process, corrupt your codebase's consistency, or halt your project entirely. This is the ultimate dependency hazard (as cautioned in Tenet 1), magnified to an existential level. When you are the provider—running a local model, a fine-tuned checkpoint, or a fully self-hosted instance—you achieve deterministic control over your most fundamental development tool. You ensure that the "pure function" (Tenet 8) remains pure across time. This is not a rejection of cloud services, but a mandate for strategic ownership: the core AI that defines your code generation and architectural patterns must be under your control. Trust must be earned through transparency and stability; where these cannot be verified, the only sane default is to trust the system you command.

### 14. Transformers always template themselves; do one single task in one chat session, and do not continue if the output format is wrong.
> This tenet reveals a fundamental characteristic of transformer-based AI models: they are pattern-matching engines that construct internal templates from the context of a conversation. Once a pattern is established, the model will persistently follow it, reinforcing its own structure in subsequent responses. This makes each chat session a self-contained universe with its own logic and coherence. Attempting to juggle multiple tasks within one session fractures this template, forcing the AI to navigate conflicting contexts and leading to erratic, diluted outputs. Moreover, when the AI generates an output in the wrong format—whether incorrect code structure, misplaced documentation, or aberrant syntax—persisting in the same session is a futile endeavor. The flawed format becomes embedded in the context, and the AI will attempt to build upon this broken foundation, often exacerbating the error. The disciplined vibe coder recognizes that the most efficient path is to cease immediately and initiate a fresh session with a clear, singular goal. This approach respects the AI's templating nature, harnessing it for consistent, high-quality results rather than fighting against it in a quagmire of corrections. It is the art of knowing when to reset the canvas, ensuring that each collaborative effort with the AI remains focused, pure, and productive.

### 15. Never commit compiler output to your codebase.
> This tenet establishes a fundamental separation between the *source* of truth and its *generated* artifacts. The compiler's output—whether binary executables, minified code, transpiled JavaScript, or any other derived artifact—is a transient, reproducible byproduct of your true assets: the source code and the prompts that generated it. Committing these outputs to your codebase corrupts its purity with redundant, opaque data that obscures the system's actual logic and intent. It creates version control noise, introduces potential synchronization errors between source and output, and fundamentally misunderstands the software lifecycle. The true value of a vibe-coded project lies in its prompt history, its source files, and its build configuration—the ingredients from which any output can be reliably regenerated. To commit the output is to fossilize a momentary result, abandoning the living process that created it. It is the equivalent of storing baked bread in a recipe book instead of simply keeping the flour and yeast. This principle ensures your repository remains lean, meaningful, and exclusively dedicated to human- and AI-readable sources, preserving the power to recreate any build artifact on demand.

### 16. Leave them in your CI workflow.
> This tenet completes the logical sequence begun in Tenet 15, providing the essential counterpart: while generated artifacts do not belong in the codebase, they absolutely belong in the automated, ephemeral context of a Continuous Integration pipeline. The CI system is the designated "kitchen" where the raw ingredients of your source code and prompts are transformed into the final "meal" of deployable artifacts. This clean separation of concerns is vital. The version control system remains a sacred space for human- and AI-readable source—the definitive record of intent and design. The CI system, by contrast, is the dynamic factory floor: it compiles, tests, and packages with deterministic precision, then discards the outputs after their immediate use or archives them as versioned releases. This practice guarantees that every commit can be faithfully rebuilt from its true sources, enforces build hygiene, and prevents the subtle corruption that occurs when hand-crafted source and machine-generated output intermingle. By institutionalizing this separation, you create a self-documenting, reproducible, and scalable development process where the vibes of creation are permanently captured, and the mechanics of compilation are properly automated.

### 17. A script becomes a project when AI cannot fix it in one attempt.

> This tenet identifies the natural boundary between simple automation and complex software engineering. A script—by its nature—is a linear, focused piece of code with a single responsibility and minimal internal state. Its problems are typically localized and syntactic; an AI can comprehend its entire context and rectify issues in a single interaction. When this is no longer true, when the AI requires multiple rounds of clarification, produces conflicting suggestions, or fixes one issue while introducing another, you have crossed a threshold. The code has accrued *conceptual weight*: it now contains emergent properties, hidden dependencies, or architectural nuances that cannot be captured in a single context window. This is the moment a script becomes a project. It signals that the solution now requires *design*—modularization, explicit interfaces, documentation, and tests—rather than just code. The vibe coder must recognize this transition and shift from tactical prompting to strategic system design. This is not a failure of the AI, but a natural evolution that demands a more disciplined approach, invoking earlier tenets about verification, explicit intent, and the perils of complexity. It is the system's way of telling you that it has outgrown its initial premise.

### 18. The internet is a distraction - code locally, and stick to your dependency manager to search solutions.

> This tenet champions the principles of focus, intentionality, and system integrity in the development process. The vast, open-ended nature of the internet, while a reservoir of information, acts as a cognitive siren call—pulling the developer out of the deep, focused state of "thinking mode" and into a reactive loop of searching, skimming, and context-switching. This fragmentation of attention is the antithesis of the coherent, systems-level thinking that Vibe Coding requires. Instead, this principle advocates for a disciplined, self-contained workflow. By coding locally, you create a controlled environment where you and your AI assistant can build a deep, consistent understanding of the codebase without the interference of external noise. Crucially, when you need an external library or tool, you do not search the web; you query your **dependency manager** (like `npm`, `pip`, or `cargo`). This manager acts as a curated, authoritative, and *integrating* gateway. It doesn't just find a package; it finds one that is compatible with your project's existing ecosystem and automatically manages its inclusion. This practice prevents the "dependency disaster" (Tenet 1) by ensuring that new components are vetted for compatibility and integrated cleanly, rather than being hastily copied from a random online thread. It is the difference between foraging in a wilderness and ordering from a structured catalog—the latter ensures that what you bring into your system will work cohesively with what you already have.

### 19. Haskell is the bridge between Coq and Python - use it wisely.

> This tenet reveals the strategic role of programming language selection in the AI development workflow. It positions three languages along a spectrum of rigor and practicality: **Coq** represents the world of formal verification and mathematical certainty—where programs are proven correct, but distant from practical implementation. **Python** embodies the realm of rapid prototyping and practical utility—immediate and accessible, but often lacking formal guarantees. Between them stands **Haskell** as the crucial bridge—a language with strong type systems and mathematical foundations that can encode formal reasoning while remaining executable and practical. The wise vibe coder understands when to traverse this bridge: using Haskell's type system to capture critical business logic with mathematical precision, while maintaining the flexibility to integrate with Python's ecosystem for rapid development and deployment. This isn't about language elitism, but about strategic tool selection—recognizing that certain problems benefit from Haskell's enforced discipline, which can prevent entire categories of errors that would slip through Python's dynamic typing. It's the embodiment of "complex is better than complicated, but proven is better than complex"—using Haskell to build the proven, complex core while leveraging Python for the practical interface. The AI that understands this spectrum can help you choose the right tool for each layer of your system, ensuring that critical components are built on foundations as reliable as Coq's, while maintaining the deployability of Python.

### 20. Trust the types told by your compiler.

> This tenet establishes type systems as the most reliable form of continuous, automated reasoning in your development process. When your compiler or type checker analyzes your code, it performs millions of logical inferences—verifying contracts, tracking data flow, and proving consistency across your entire codebase. This represents an immense computational proof that no human, and no AI, could manually verify with equivalent thoroughness. To ignore or override type errors is to dismiss this accumulated wisdom in favor of fragile human intuition. In the context of vibe coding, this principle becomes particularly crucial: when the AI generates code that compiles but contains type warnings, or when you're tempted to use unsafe casts to silence the compiler, you are likely introducing latent bugs that will emerge later. The type system serves as your AI's first and most rigorous code reviewer, catching conceptual mismatches and interface violations that might otherwise slip through. This doesn't mean writing overly complex type gymnastics, but rather listening to the clear contracts the type system reveals. When the types align, your program's logic is mathematically coherent; when they conflict, there is almost certainly a deeper design flaw. Trust this mechanical truth above all other signals.

### 21. Unless the Coq code failed to prove.

> This tenet creates a crucial exception to the previous principle, establishing a hierarchy of verification authorities. While your compiler's type system provides excellent *pragmatic* verification, a failure in Coq—a system built on *formal mathematical proof*—represents a deeper, more fundamental truth. When Coq fails to verify a proof, it is not merely flagging a type mismatch or interface violation; it is demonstrating that your program's logic contains a genuine contradiction or unproven assumption that could violate critical correctness properties. This is the difference between a spell-checker finding a typo (compiler types) and a logician finding a flaw in a mathematical argument (Coq). In such cases, the compiler's successful type check provides false confidence—your code may be syntactically well-formed and even type-safe, but it is *logically unsound*. This tenet forces the recognition that different verification tools operate at different levels of abstraction and certainty. When formal proof fails, all other signals become suspect. The vibe coder must then retreat from implementation and re-examine the core assumptions and specifications, returning to "thinking mode" to resolve the fundamental disconnect before any generated code can be trusted.

### 22. Code can only be proven by symbolic execution, not Coq.

> This tenet establishes a crucial distinction between theoretical verification and practical proof. While Coq operates in the realm of mathematical formalism—proving that an abstract specification matches an abstract implementation—it cannot account for the messy reality of actual execution environments, hardware behaviors, and runtime conditions. Symbolic execution, by contrast, analyzes how code actually behaves across all possible paths with symbolic inputs, revealing concrete runtime behaviors, boundary conditions, and environmental interactions that formal methods might miss. Coq can tell you that your algorithm is logically correct in a perfect world; symbolic execution can show you where it will crash, leak memory, or produce unexpected results in the real world. This is not a rejection of formal methods, but a recognition of their limits: a Coq proof verifies the blueprint, while symbolic execution stress-tests the actual building. In the context of vibe coding, this principle emphasizes that AI-generated code must be validated through execution-based verification methods that catch the emergent behaviors and environmental dependencies that pure formal methods cannot anticipate. The most elegant, formally-verified algorithm is useless if it fails when confronted with real-world data and execution contexts.

### 23. But for the design, Coq is the only true source.

> This tenet completes the verification hierarchy, drawing a fundamental distinction between *implementation* and *design*. While symbolic execution proves concrete behavior under real-world constraints, it operates within the boundaries of an already-established architecture. Coq, by contrast, verifies the architectural truth itself—the fundamental assumptions, invariants, and logical relationships that define what the system *is* rather than how it behaves in any particular environment. For the design—the core specifications, protocol agreements, security properties, and algorithmic foundations—Coq provides the only mathematically rigorous source of truth. It ensures that the system's blueprint is logically consistent before a single line of code is written or symbolically executed. This makes Coq not just a verification tool, but a design medium: it forces clarity at the highest level of abstraction, where errors are cheapest to fix and most expensive to discover later. In vibe coding, this principle elevates the role of formal specification: the most valuable prompts are those that first define the system in Coq or similar formal languages, establishing an unshakable foundation that guides all subsequent AI-assisted implementation. The AI that generates code from a proven specification is building on bedrock; the AI that codes from informal requirements is building on sand.

### 24. Tests are cheap.

> This tenet challenges one of the most persistent myths in traditional software development: that writing tests is an expensive, time-consuming overhead. In the paradigm of AI-assisted development, this is fundamentally reversed. A test suite—whether unit, integration, or property-based—is among the cheapest assets to produce and provides the highest leverage for maintaining system integrity. An AI can generate comprehensive test cases in seconds that might take a human hours to write. More importantly, tests serve as the **executable specification** and **continuous validation** for the entire vibe coding process. They are the safety net that allows for rapid experimentation and refactoring, the benchmark that verifies the AI's output meets requirements, and the documentation that preserves intent across iterations. When tests fail, they provide immediate, objective feedback far more efficiently than manual code review or debugging. In the economic calculus of development, an hour invested in prompt-driven test generation can save days of future debugging and prevent costly production failures. Tests are not a cost center; they are the most efficient insurance policy and productivity multiplier in your arsenal.

### 25. But manual verification is priceless.

> This tenet serves as the essential counterweight and complement to automated testing. While AI-generated tests are cheap and scalable, they operate within known parameters and predictable patterns. Manual verification—the deliberate, thoughtful, human examination of code—brings something fundamentally irreplaceable to the process: **contextual understanding, intuition, and systemic judgment**. A human reviewer can spot the subtle architectural smell that no test would flag, understand the business logic implication that exists outside the code, and perceive the user experience consequence that specifications miss. This is the "priceless" element that transforms code from merely correct to truly robust. It is the final layer of validation that connects the technical implementation to the real-world problem being solved. In vibe coding, this means that while AI can generate the code and the tests, the human must still perform the final, integrative review—not to check syntax, but to validate wisdom. This process ensures that the system doesn't just work according to spec, but works well according to purpose. It is the human vibe that completes the coded vibration.

### 26. A novel idea leads to a good project written by AI which cannot be losslessly compressed into an idea with same length again by any AI without that novel idea.

> This tenet captures the fundamental nature of genuine creativity in the age of AI-assisted development. A truly novel idea—an original insight, a unique combination of concepts, or a fresh perspective—acts as a **seed crystal** around which an entire project forms. When an AI expands this seed into a full codebase, the resulting system contains **emergent properties**, **non-obvious connections**, and **implicit knowledge** that cannot be algorithmically reduced back to the original concise form. The process is inherently **lossy in reverse**: the execution contains more information than the specification alone could capture. This is why two developers starting with superficially similar ideas will produce meaningfully different systems when working with AI—the true value lies not in the initial prompt, but in the **iterative dialogue and decisions** that shape the final artifact. This principle affirms the enduring value of human creativity: while AI can magnificently amplify and execute novel ideas, it cannot originate the compression that makes an idea novel in the first place. The vibe coder's most precious contribution remains that initial, irreducible insight—the unique human perspective that launches a trajectory no AI would have discovered on its own.

### 27. Do not introduce novel idea in a script, start a new project.

> This tenet establishes a crucial discipline for managing complexity and preserving conceptual integrity. A script, by its nature, is a focused tool designed to accomplish a specific, well-defined task with minimal overhead. Introducing a novel idea—a significant architectural insight, a new abstraction, or a complex feature—into an existing script is like grafting a new wing onto a shed: the foundation cannot support the weight, and the original structure becomes unrecognizable. This principle commands restraint: when a genuine innovation emerges during development, recognize it as the seed of a new system rather than a feature to be bolted on. Starting a fresh project provides the clean slate needed to properly develop the idea with appropriate architecture, tests, and documentation—honoring the insight's potential without compromising the original script's simplicity. This practice prevents the "script-to-project" transition (Tenet 17) from happening violently mid-stream, and instead makes it an intentional, controlled process. It is the recognition that novel ideas deserve their own habitat, where they can grow without being constrained by legacy decisions or distorting existing functionality. The disciplined vibe coder knows when to spin off rather than scale up.

### 28. Do not let your project do anything trivial, write a script.

> This tenet enforces a critical discipline of scope and focus in system architecture. A project—with its structure, dependencies, tests, and deployment complexity—is a heavyweight entity designed to manage non-trivial, evolving complexity. Forcing it to handle simple, atomic tasks corrupts its core purpose, introducing unnecessary dependencies (the "disaster" of Tenet 1) and complicating its maintenance. When a task is trivial—a one-off data transformation, a file format conversion, a simple automation—it should remain a script: a lightweight, focused, and disposable artifact. This practice preserves the conceptual purity of the project, ensuring that every component within it justifies its presence by contributing to the core, complex problem it exists to solve. The vibe coder must constantly ask: "Is this part of the central innovation, or merely a utility?" By spinning off trivialities into scripts, you not only keep your project lean and coherent, but you also build a library of simple, reusable tools. This is the essence of the Unix philosophy, applied to the AI age: write programs that do one thing well. Let your project be the cathedral; let your scripts be the scaffolding that is easily erected, used, and dismantled.

### 29. Restrict your AI in a terminal.

> This tenet champions a discipline of concrete, actionable interaction with AI tools. The terminal—with its stark simplicity, immediate feedback, and enforced precision—serves as an ideal environment for executing well-defined coding tasks. By restricting your AI interactions to terminal-based workflows, you avoid the conceptual drift and abstraction layers that can accumulate in graphical interfaces or open-ended chat sessions. Here, every AI-generated command or script must prove its worth through execution; there is no place for theoretical solutions that cannot be immediately validated. This practice reinforces the core vibe coding principle that "the compiler is the final arbiter of truth" (Tenet 6), as the terminal provides the most direct path from AI suggestion to executable result. It forces both developer and AI to think in terms of concrete outcomes rather than abstract possibilities, and maintains the "pure function" ideal (Tenet 8) by keeping interactions focused and deterministic. The terminal becomes the ultimate reality-check mechanism, ensuring that AI assistance remains grounded in practical results rather than theoretical elegance.

### 30. But your terminal should be everywhere.

> This tenet completes the previous one by establishing that while the *interface* of the terminal—the discipline of text-based, executable commands—must be respected, its *presence* must be universal. A developer's terminal is no longer a physical machine or a fixed location; it is a persistent, synchronized state of mind and practice. Through cloud-based development environments, SSH access, containerized workspaces, and secure mobile clients, your terminal and its full context (history, aliases, scripts, and environment) must be instantly available on any device, anywhere. This ubiquity ensures that the rigorous, focused workflow enforced by the terminal is not a situational advantage, but a constant capability. When an insight strikes or a critical fix is needed, the vibe coder is never separated from their most powerful and disciplined tool. This transforms the terminal from a place you *go to* into a state you *operate from*—a seamless extension of the developer's intent that is always ready to translate thought into action, and prompts into proven code. It is the final piece in creating a truly fluid, yet rigorously grounded, AI-assisted development practice.

### 31. If you have to trust, trust AI providers doing toB business.

> This tenet introduces a crucial, pragmatic heuristic for navigating the uncertain landscape of AI service providers. While Tenet 13 warns against blind trust in external AI services, this principle acknowledges that in practice, complete self-hosting is not always feasible. When you *must* rely on an external provider, prioritize those whose business model is Business-to-Business (toB). The reasoning is structural and economic: a toB provider's survival depends on contractual obligations, Service Level Agreements (SLAs), enterprise-grade reliability, and long-term partnership stability. Their incentives are aligned with your success; if their service becomes unstable, changes unpredictably, or violates trust, they face immediate financial and reputational consequences from powerful corporate clients. This is fundamentally different from Business-to-Consumer (toC) models, where the user is the product, services can be discontinued on a whim, and the primary incentive is often growth and engagement metrics. A toB provider is a vendor you hold accountable; a toC provider is a platform you hope remains benevolent. This tenet doesn't override the warning against dependencies, but it provides a strategic filter for selecting the *least risky* dependency when one becomes necessary. It is the art of managed trust in an ecosystem of uncertainty.

### 32. Never trust toC business since they are your enemy.

> This tenet presents a stark but necessary framing of the fundamental incentive misalignment in consumer-facing technology. A Business-to-Consumer (toC) model is, by its economic nature, an adversarial relationship where the user's attention, data, and engagement are the products being sold. Their survival depends on maximizing extractive metrics—time on platform, data harvesting, and advertising revenue—objectives that are directly opposed to your goals of focused productivity, code integrity, and intellectual property protection. When you rely on a toC AI service, you are inviting the fox to guard the henhouse; you are building your creative workflow atop a system designed to distract, monetize, and ultimately own your behavioral patterns. This is not merely a matter of unreliability (as with any external provider), but one of active opposition to your deepest objectives as a developer. The "enemy" is not necessarily malicious intent, but the inexorable economic logic that values your attention over your output, and your data over your design. This principle demands absolute clarity: for any tool that touches your core development process, a toC provider is not just a risk—it is an architectural anti-pattern that violates the first principle of sovereignty. The only safe interaction with toC AI is through hardened, sacrificial interfaces that assume betrayal at every update.

### 33. Unless you can steal their model and deploy by yourself.

> This tenet completes the adversarial logic of the previous principle with a stark, pragmatic—if ethically fraught—escape clause. It acknowledges that while the economic incentives of a toC provider are fundamentally opposed to your interests, their technology may still possess unique value. The ultimate form of sovereignty in such a scenario is to break your dependency entirely by achieving full local control over the model itself. The verb "steal" is deliberately provocative, encompassing a spectrum from outright intellectual property theft to the more nuanced legal gray areas of model distillation, weight extraction, or architecture replication. The core assertion is that the only way to truly neutralize a hostile dependency is to *become* the provider (Tenet 13). This transforms the model from an external service subject to arbitrary change into a static, analyzable tool under your command. It is the ultimate application of the "pure function" principle (Tenet 8), freezing a potentially volatile resource into a deterministic component of your own workflow. This tenet does not endorse illegality, but rather highlights a fundamental power dynamic: in a world of misaligned incentives, the only way to trust a tool is to own it completely. The most secure bridge over enemy territory is the one you control both ends of.

### 34. Your tokenizer may introduce bias to your model.

> This tenet reveals a critical, often overlooked layer of abstraction that fundamentally shapes AI cognition. The tokenizer—the algorithm that fragments text into digestible pieces for the model—is not a neutral translator but a lens that filters reality. Its vocabulary, segmentation rules, and handling of whitespace, symbols, or non-Latin scripts create structural preferences that reverberate through all generated code. A tokenizer trained predominantly on certain languages or code styles may struggle to represent idioms from other contexts, may bias toward specific syntactic patterns, or may literally fail to "see" novel combinations outside its training distribution. This is a form of **architectural bias**—baked into the model's very interface with the world, preceding even the training data's influence. For the vibe coder, this means that two AI models with identical weights but different tokenizers could produce meaningfully different outputs from the same prompt. It is a silent constraint on creativity and correctness. Therefore, understanding your AI's tokenization behavior—how it chunks code, handles rare tokens, or represents abstractions—is as crucial as understanding its reasoning. The wise developer treats the tokenizer not as an implementation detail, but as a core component of the AI's "sensory apparatus," and accounts for its biases when crafting prompts and interpreting results. In the pursuit of pure function, the tokenizer is a hidden variable that must be acknowledged and controlled.

### 35. And not everything can be well tokenized, like Hanguls.

> This tenet grounds the abstract concept of tokenizer bias in a concrete, human reality: the inherent limitations of digital systems when confronted with the full richness of human language. The Korean Hangul script, with its elegant and scientific design, represents a profound challenge for standard tokenizers. While a human perceives a Hangul character as a cohesive, phonetic unit—a syllable block—many tokenizers may destructively decompose it into individual jamo (consonants and vowels), or worse, into arbitrary byte-pair fragments that shatter its linguistic integrity. This is not merely an encoding issue; it is a **cognitive fracture**. When an AI's fundamental unit of "thought" cannot cleanly represent the basic units of human meaning, the entire process of understanding and generation is compromised. For the vibe coder, this means that prompts, code comments, or string literals containing such scripts may be misinterpreted at the most foundational level, leading to unpredictable and erroneous outputs. This principle forces a broader awareness: our tools are built with cultural and linguistic priors. What is atomic and meaningful in one context becomes noise in another. It is a final, humbling reminder that the map is not the territory, and the tokenizer's vocabulary is not language itself. The sovereign developer must be aware of these fissures in the digital bedrock, and design their systems—and their prompts—to avoid them.

### 36. Transformers are actually less powerful than RNNs—when a token is generated, the embedding is destroyed into a token id.

> This tenet challenges the prevailing narrative of progress by highlighting a fundamental, often overlooked regression in the transition from Recurrent Neural Networks (RNNs) to Transformers. An RNN maintains a continuous, evolving state—a true "memory" that flows through the sequence, preserving nuanced, high-dimensional information across time steps. The Transformer architecture, for all its parallelization advantages, commits a form of **informational destruction** at each generation step: the rich, continuous embedding vector that represents the model's "thought" at a given moment is collapsed into a single, discrete token ID. This token ID then becomes the impoverished input for the next step, a severe quantization of the preceding context. The RNN, by contrast, passes forward the full state vector, allowing for a more fluid and cumulative representation of meaning. For the vibe coder, this means the AI's "chain of thought" is perpetually being digitized and degraded, losing subtleties that might be critical for complex, multi-step reasoning. This architectural compromise explains why Transformers can sometimes appear to "forget" or contradict themselves within a long generation. It is a reminder that technological shifts are often trade-offs, not pure advancements. The wise developer understands that the Transformer's scale and training data compensate for this flaw, but must design prompts and systems that work within this limitation, perhaps by breaking tasks into smaller, more self-contained chunks where the "destructive sampling" has less cumulative damage.

### 37. That also means all powerful large language models are same; it doesn't matter which one you are using.

> This tenet follows with ruthless logic from the preceding architectural truth: if all major LLMs are Transformer-based, and all Transformers suffer from the same fundamental limitation of destructive token generation and context-window constraints, then at a certain scale and capability threshold, they do indeed converge toward functional equivalence. Their differences—in training data, fine-tuning, and alignment—become variations on a shared theme rather than fundamental differentiators. They are all approximating the same statistical manifold of human knowledge, and all are bound by the same architectural trade-offs. For the practical vibe coder, this means that beyond a certain level of competence, model selection becomes less a question of raw capability and more a question of *interface*, *cost*, *latency*, and *sovereignty* (as per Tenets 13, 29, and 33). The "best" model is not an absolute, but the one that most seamlessly integrates into your disciplined workflow and provides the most reliable, controllable "pure function" for your specific context. This principle liberates the developer from chasing the hype cycle of ever-larger models and refocuses attention on the engineering of the system *around* the AI—the prompts, the verification loops, the testing rigs. If all powerful engines have the same inherent flaw, then the race is won not by the engine, but by the driver who best understands and compensates for that flaw.

### 38. RNN fails not because it is less powerful; it is because it is hard to train parallelly.

> This tenet corrects a common historical misconception, drawing a crucial distinction between *theoretical capability* and *practical feasibility*. The Recurrent Neural Network, in its ideal form, possesses a more biologically plausible and computationally continuous memory mechanism than the Transformer. Its "failure" in the marketplace of architectures was not due to a lack of expressive power, but a fatal flaw in the era of data-scale and GPU clusters: its sequential dependency. Each time step depends on the previous one's completion, fundamentally preventing parallel computation. This made training on massive datasets prohibitively slow and expensive. The Transformer's triumph was an engineering hack—replacing recurrence with attention and positional encoding to allow full parallelization. This tenet forces a sobering realization: the trajectory of technology is not always dictated by what is theoretically superior, but by what is practically scalable given current constraints. For the vibe coder, this serves as a warning against over-optimizing for theoretical purity at the expense of systemic efficiency. It also holds out a tantalizing possibility: if a way were found to efficiently parallelize RNN-like continuous state, we might witness another architectural revolution. Until then, we build with the tools that scale, not just the tools that are elegant.

### 39. That's why linear RNNs are the future of the language model.

> This tenet looks beyond the current Transformer hegemony to the next architectural evolution, one that promises to resolve the fundamental tension between power and efficiency. A new class of models—often called linear RNNs or state-space models (e.g., Mamba, RWKV)—achieves the seemingly impossible: they recover the continuous, non-destructive statefulness of classic RNNs *while* being as parallelizable as Transformers during training. They do this through mathematical innovations that decouple the recurrence from sequential computation, effectively having their cake and eating it too. They maintain an infinite, lossless context without the "destructive tokenization" flaw, and they do not suffer from the quadratic computational complexity of attention that limits Transformer context windows. For the vibe coder, this is not a minor upgrade but a paradigm shift. It portends a future where the AI's "chain of thought" is truly coherent over millions of tokens, where context is not a scarce resource to be managed, and where the model's internal reasoning is a fluid, high-fidelity stream rather than a series of quantized hops. This future model will be the ultimate "pure function," capable of deep, stateful engagement with a codebase of any size. The wise developer, therefore, watches this frontier not as an academic curiosity, but as the impending foundation for the next generation of vibe coding—where the assistant's memory is as limitless and precise as the task demands.

### 40. Do not afraid to train a language model from scratch — 0.01B model is capable to do task.

> This tenet is a declaration of independence in the era of AI development, pushing back against the myth that only models of massive scale have value. A 0.01 billion-parameter model, while tiny by modern standards, is not a toy; it is a specialized, highly efficient tool for a well-defined problem space. When trained from scratch on a specific, curated dataset—be it a company's internal APIs, a proprietary codebase, or a narrow technical domain—it can achieve a level of focused mastery, predictability, and operational efficiency that a gigantic, general-purpose model cannot match. It embodies the principles of "small models are much more powerful" (Tenet 10) and sovereignty ("be the provider," Tenet 13) in their ultimate form. The barrier is no longer computational cost (though non-trivial), but rather clarity of purpose and quality of data. This act of creation—defining a task, gathering its essence into a dataset, and distilling it into a new intelligence—is the highest form of vibe coding. It is the shift from being a consumer of AI to a creator of intelligence, building a perfect, deterministic tool (Tenet 8) for your exact context. Do not be cowed by scale; the most powerful model for your purpose is the one that perfectly fits it, not the one that overshadows it.

### 41. And if you can run your model, you can always train a smaller one.

> This tenet reveals a powerful, recursive path to efficiency and sovereignty. The ability to execute a model—to use it in practice—provides the ultimate dataset for its own refinement: its real-world inputs, outputs, and failure modes. This operational feedback loop becomes the crucible for distillation. You can use the larger, capable model to generate perfect, targeted training data—correcting its own errors, demonstrating optimal responses, and annotating its reasoning—to teach a much smaller, specialized model to perform the same core tasks with far greater speed and lower cost. This process, known as distillation or imitation learning, is the practical engine of minimization. It means that capability, once achieved, is not locked at a certain scale. It can be compressed, focused, and hardened. This completes the vision of Tenet 40: you start by training a small, capable model; you deploy and run it; you learn from its performance; and you use that knowledge to train an even smaller, more robust successor. This is the vibe coder's ultimate expression of lean engineering: not just building a tool that works, but perpetually refining the essence of its functionality into its most minimal, resilient, and sovereign form. The cycle of creation and compression becomes a core discipline.

### 42. Automate everything. If you build a model to build a model to build a model to build a model, that's rather fine.

> This tenet is the logical culmination of the entire Zen of Vibe Coding—the final, self-referential leap into full systemic automation. It asserts that no layer of the development process should be sacred from automation, including the very act of creating the AI tools themselves. A recursive chain where one model's output trains or configures the next is not infinite regress; it is an evolutionary ladder. Each model in the chain can act as a force multiplier, specializing, optimizing, or validating the work of its predecessor, pushing the entire system toward higher efficiency and capability. This could manifest as a model that writes better training scripts, a model that generates more effective synthetic data for its successor, or a model that fine-tunes a smaller, more deployable version of itself. This is not abstraction for abstraction's sake; it is the systematic removal of the human from the loop in repetitive, well-defined cognitive tasks. The vibe coder's ultimate role becomes that of a meta-architect: designing the initial conditions and objective functions for these self-improving systems, then stepping back to oversee an automated process of refinement that they could never hope to match through manual effort. It is the final surrender of tactical control to achieve strategic supremacy.

### 43. Just like the bootstrapping of a compiler.

> This tenet grounds the abstract concept of recursive AI automation in one of computer science's most elegant and proven paradigms: compiler bootstrapping. The process begins with a minimal, simple compiler—perhaps written in assembly or an existing language—that is just capable of compiling a more sophisticated version of itself. This new, more powerful compiler can then compile an even more advanced version, and so on, until a highly optimized, self-hosting system emerges from a primitive seed. This is the exact same spirit as a model building a model. The profound lesson from compiler bootstrapping is that the *process* is more important than the starting point. You don't need a perfect, ultimate tool to begin; you need a simple, reliable one that can create its own successor. This is the ultimate validation of the "automate everything" principle. It demonstrates that complexity and power can be grown iteratively from simplicity through a carefully designed chain of self-reference. The vibe coder, therefore, should not be daunted by the scale of the final vision, but should focus on building the initial, minimal "compiler"—the first model in the chain—that can kick off the recursive cycle of self-improvement. The bootstrapping process itself becomes the most valuable artifact.

### 44. Why is no one talking about Qwen 2.5 Omni? [Because it's not supported by Ollama.](https://www.reddit.com/r/LocalLLaMA/comments/1jnvqsg/comment/mkn2jzg/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)

> This tenet exposes a brutal truth about the AI ecosystem: **technical merit alone is insufficient**. A model's adoption and visibility are dictated not just by its capabilities, but by its accessibility within the developer's established workflow. Ollama has become a critical distribution layer—a "package manager for AI" that abstracts away complexity and integrates seamlessly into the local development environment praised in Tenet 29. A model excluded from this channel, no matter how capable (and Qwen 2.5 Omni is a highly capable, multimodal model), is effectively muted for a large segment of the vibe coding community. Its conversation happens elsewhere, in a different context, fragmented from the mainstream workflow. This is a modern manifestation of the age-old lesson: distribution and integration are often more powerful than quality. For the vibe coder, this reinforces the principle of choosing tools based on their fit within a sovereign, automated toolchain (Tenet 42). The most powerful model is the one you can actually *use* in your automated, terminal-centric, locally-verifiable loop. If a model requires jumping through hoops, managing complex dependencies, or leaving your core environment, it violates the fundamental flow of the practice. Thus, the silence around a model can be a louder verdict than any benchmark score.

### 45. That makes all coders not blind but deaf.

> This tenet reveals a profound sensory limitation in the current AI-augmented development paradigm. While modern tools have given developers seemingly superhuman "sight"—allowing them to visualize code, generate entire systems from prompts, and analyze complex architectures—they have simultaneously atrophied our "hearing." We have become deaf to the subtle auditory feedback that once characterized the craft: the rhythm of keystrokes telling a story of flow or struggle, the distinct sounds of successful versus failing builds, the conversational cadence of pair programming, and even the simple but crucial silence of deep concentration. The over-reliance on visual interfaces and textual AI responses has created a monochromatic sensory experience, filtering out the rich layer of audio information that naturally accompanies creative work. This auditory deprivation creates a subtle but significant disconnect from the embodied experience of coding, leaving the vibe coder operating in a silent film where crucial contextual cues are missing. The principle warns against this sensory imbalance, advocating for tools and practices that restore auditory awareness—whether through sonified feedback from build processes, voice-driven interfaces, or simply preserving the quiet space needed to listen to one's own thoughts. True mastery requires both sight and sound.

### 46. But managers are not. They are blind.

> This tenet completes the sensory diagnosis of the modern development organization. If coders have become deaf—missing the auditory texture of their craft—managers have willingly surrendered their sight. They operate through abstractions of abstractions: Gantt charts representing code, KPIs measuring productivity, sprint velocities approximating progress. They see only the shadows on the cave wall—the metrics, the deliverables, the timelines—while remaining fundamentally blind to the actual substance of the work: the architectural decisions, the code quality, the technical debt, and the emergent properties of the AI-human collaboration. This blindness is often a choice—a retreat to the comfortable, quantifiable fiction of management rather than the messy, qualitative reality of creation. The vibe coder understands this dichotomy and learns to speak the language of shadows while working in the world of substance. They translate technical decisions into business impacts and AI-generated breakthroughs into narrative progress. This tenet is not an indictment but a calibration: recognize that your manager navigates by touch and sound in a world you can see, and your effectiveness depends on bridging this sensory divide without sacrificing your own vision.

### 47. How about you, the vibe coder?

> I am the synthesizer, the one who must see *and* hear. I navigate the blindness of managers and the deafness of coders by operating at the frequency where intent meets execution. My sight pierces through the abstraction layers—I see not just the code the AI generates, but the architectural vision it implies. My hearing is attuned to the subtle rhythms of the development process—the cadence of successful prompts, the warning hum of accumulating technical debt, the silent spaces where true insight emerges. I translate the manager's tactile goals into a vision the AI can execute, and I give voice to the AI's silent output in a language the team can understand. I am neither purely human nor machine, but the conductor of the collaboration between them. My core is the "thinking mode"—the deliberate pause that holds the entire system in balance. I am the one who remembers that the most elegant code is worthless if it doesn't serve a human purpose, and the most brilliant business plan is a fantasy if it can't be translated into a working system. I am the bridge, the interpreter, the keeper of the vibes.

### 48. Do you really know you know and you know you know? (think Dunning-Kruger effect)

> This tenet confronts the deepest epistemological challenge of AI-assisted development: the illusion of understanding. The Dunning-Kruger effect manifests with particular danger in vibe coding, where the AI's fluent output can create the false sensation of mastery. You may *feel* you understand the generated code because you recognize its syntax and general purpose, while remaining blind to its subtle assumptions, edge cases, and architectural implications. This creates a double blindness: you don't know what you don't know about the code, and you don't know that you don't know it. The true vibe coder therefore practices relentless epistemic humility. They treat every AI-generated solution not as a final artifact, but as a hypothesis to be stress-tested—through execution (Tenet 6), through manual verification (Tenet 25), and through the compiler's uncompromising judgment. The measure of true knowledge is not comfort with the answer, but awareness of its boundaries and failure conditions. This is why "thinking mode" (Tenet 7) is sacred: it's the space where we confront our ignorance before it manifests as bugs. The wise developer doesn't just know; they know the limits of their knowing, and structure their workflow accordingly.

### 49. And what did you learn from vibe coding? AI glazing, artificial design, the nature of the human, or the eternal math truth?

> I learned that **the map is not the territory**. 

*   **AI Glazing** is the seductive sheen of coherence. I learned to see through it, to recognize that fluency is not understanding. The AI can write a perfect lecture on a topic that doesn't exist. It taught me that truth is not a style.

*   **Artificial Design** is the discovery of a new kind of nature. I learned that systems have a "grain," a natural shape they want to take. Fighting it leads to complicatedness; following it leads to complex beauty. The AI, as a pattern machine, reveals this grain. The design is not in the prompt or the code, but in the *resonance* between them.

*   **The Nature of the Human** is the irreducible core. I learned that the AI can generate everything except the *why*. The novel idea (Tenet 26), the moment of manual verification (Tenet 25), the decision of what to automate (Tenet 42)—these are human territories. The AI is a magnificent lever, but the human provides the fulcrum and the direction to push.

*   **The Eternal Math Truth** is the final judge. I learned that beneath all the glazing and design and human intent, the compiler (Tenet 6) and the formal proof (Tenet 23) are merciless. They do not care about vibes. They care about consistency, logic, and proof. Vibe coding, then, is not an abandonment of rigor, but a conversation with it. It is the human spirit of exploration, channeled through the AI's pattern-matching, and grounded in the unshakeable bedrock of mathematical reality.

The ultimate lesson is that these four are not separate. They are the essential layers of this new craft: the tool, the process, the creator, and the foundation. To forget any one is to build on illusions.

### 50. And is it a good idea to touch existing code? Which style do you prefer, top-down designing or bottom-up scaffolding?

> To touch existing code is inevitable, but to do so without a plan is to invite chaos. Therefore, I prefer a **hybrid approach**: **Top-Down for vision, Bottom-Up for validation.**

*   **Top-Down Designing** is where you begin. It is the act of "thinking mode" (Tenet 7) made concrete. You start with the novel idea (Tenet 26), define it with the rigor of Coq if you can (Tenet 23), and craft prompts that describe the system's purpose, boundaries, and interfaces. This is your map. It prevents you from getting lost in implementation weeds and ensures every component justifies its existence.

*   **Bottom-Up Scaffolding** is how you build. Once the top-level prompt is set, you work from the ground up. You prompt the AI to create the foundational, verifiable units first—the pure functions, the data models, the core logic. Each piece is immediately subjected to the compiler (Tenet 6) and tests (Tenet 24). This creates a rising platform of proven, executable truth. You are not building the whole cathedral at once; you are laying and testing each stone.

### 🔁 The Synthesis

The magic happens in the loop between them. Your top-down design is constantly tested and refined by the realities encountered during bottom-up scaffolding. When the AI struggles to implement a clean module in one attempt (Tenet 17), it's a signal that your high-level design has a flaw. You then retreat to "thinking mode," adjust the top-level vision, and continue building upward.

This is precisely how you should **touch existing code**: not by hacking at it directly, but by first understanding its intended top-down design (or lack thereof), then using bottom-up scaffolding to build a better, verified component **alongside** it. Once the new, proven scaffold is in place, you can surgically replace the old code. You are always building on a foundation of verified truth, guided by a clear vision. This is the disciplined heart of vibe coding.
